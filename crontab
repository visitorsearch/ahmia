# m h  dom mon dow   command
#
# EVERY HOUR
# Every hour destroy possible IP addresses from the error logs
0 * * * * sed -i s/'\['client.*'\]'/'\['0.0.0.0'\]'/ /var/www/visitor/error/error.log 2>&1
0 * * * * sed -i s/'\['client.*'\]'/'\['0.0.0.0'\]'/ /var/www/visitor/error/hs_error.log 2>&1
#
# EVERY DAY
# Check every day statistics from Tor2web nodes.
0 1 * * * timeout 1800s python /var/www/visitor/tools/get_tor2web_domains.py >>/var/www/visitor/error/tools_get.log 2>&1
# Move Tor2web stats to the database
0 2 * * * timeout 9000s python /var/www/visitor/tools/use_popularity_data.py >>/var/www/visitor/error/tools_popularity.log 2>&1
# Check every day which hidden services are online and try to download description.json from them.
0 3 * * * timeout 60000s python /var/www/visitor/tools/test_hidden_services.py >>/var/www/visitor/error/tools_test.log 2>&1
#
#EVERY WEEK
# Once a week analyze and remove the log files
1 0 * * 1 python /var/www/visitor/tools/access_log_analyser.py
2 1 * * 1 echo "" > /var/www/visitor/error/error.log
3 1 * * 1 echo "" > /var/www/visitor/error/access.log
4 1 * * 1 echo "" > /var/www/visitor/error/hs_error.log
5 1 * * 1 echo "" > /var/www/visitor/error/hs_access.log
# Once a week check the backlinks
#6 1 * * 1 timeout 600000s python /var/www/visitor/tools/gather_backlinks_data.py >>/var/www/visitor/error/tools_backlinks.log 2>&1
# Once a week create database backup
7 1 * * 1 pg_dump -U ahmia_login ahmia_db -f /var/www/visitor/backups/sql/$(date -d "today" +"%Y-%m-%d")-db_backup.sql
# Create a snapshot from the addresses with their descriptions
8 1 * * 1 curl -i "Content-Type: application/json" https://ahmia.fi/address/ > /var/www/visitor/backups/addresses/$(date -d "today" +"%Y-%m-%d")-addresses_snapshot.json
#
#
# Create Tor2web stats
0 5 * * 1 python /var/www/visitor/tools/read_tor2web_stats.py
#
#
#Download new port scan results
30 1 * * 6 scp root@<scanner_server_ip>:/home/juha/hsportscanner/nonweb_services.json /var/www/visitor/ahmia/static/log/
